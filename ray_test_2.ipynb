{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "EPOCHS = 20\n",
    "N_TRIALS = 20\n",
    "CLASSES = 10  # StateFarm has 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    \"\"\"\n",
    "    Defines the pretrained ViT_B_16 model with a modified last linear layer and frozen base layers.\n",
    "    \"\"\"\n",
    "    pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "    pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights)\n",
    "    \n",
    "    # Freeze the base parameters\n",
    "    for parameter in pretrained_vit.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    # Modify the final layer for 10 classes (StateFarm)\n",
    "    pretrained_vit.heads = nn.Linear(in_features=768, out_features=CLASSES)\n",
    "    return pretrained_vit, pretrained_vit_weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(transform):\n",
    "    \"\"\"\n",
    "    Creates the train and validation dataloaders.\n",
    "    \"\"\"\n",
    "    train_dir = \"/home/sur06423/wacv_paper/wacv_paper/data/imbalanced_v2/train\"\n",
    "    val_dir = \"/home/sur06423/wacv_paper/wacv_paper/data/imbalanced_v2/validation\"\n",
    "    \n",
    "    trainset = ImageFolder(root=train_dir, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "    valset = ImageFolder(root=val_dir, transform=transform)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=1024, shuffle=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, device):\n",
    "    \"\"\"\n",
    "    Training function.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss, total_correct = 0, 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "    return total_loss / len(train_loader.dataset), total_correct / len(train_loader.dataset)\n",
    "\n",
    "def validate_model(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Validation function.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss, total_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "    return total_loss / len(val_loader.dataset), total_correct / len(val_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainViT(tune.Trainable):\n",
    "    \"\"\"\n",
    "    Trainable class for Ray Tune.\n",
    "    \"\"\"\n",
    "    def setup(self, config):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model, transforms = define_model()\n",
    "        self.model.to(self.device)\n",
    "        self.train_loader, self.val_loader = get_data_loaders(transforms)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "\n",
    "    def step(self):\n",
    "        train_loss, train_acc = train_model(self.model, self.optimizer, self.train_loader, self.device)\n",
    "        val_loss, val_acc = validate_model(self.model, self.val_loader, self.device)\n",
    "        return {\"train_loss\": train_loss, \"train_acc\": train_acc, \"val_loss\": val_loss, \"val_acc\": val_acc}\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"model.pth\")\n",
    "        torch.save({\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "        }, checkpoint_path)\n",
    "        return checkpoint_dir\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"model.pth\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:46:01,347\tINFO worker.py:1777 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CPU': 24.0, 'memory': 363576301773.0, 'node:__internal_head__': 1.0, 'object_store_memory': 160104129331.0, 'GPU': 4.0, 'node:10.56.7.46': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import os\n",
    "\n",
    "ray.shutdown()  # Ensure Ray is not already running\n",
    "ray.init(num_cpus=24, num_gpus=4, include_dashboard=True)  # Explicitly set the number of GPUs\n",
    "\n",
    "print(ray.available_resources())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated LD_LIBRARY_PATH:\n",
      "/usr/lib/xorg-nvidia-525.116.04/lib/x86_64-linux-gnu:/usr/lib/xorg/lib/x86_64-linux-gnu:/usr/lib/xorg-nvidia-535.113.01/lib/x86_64-linux-gnu:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the directories to be added to LD_LIBRARY_PATH\n",
    "library_paths = [\n",
    "    \"/usr/lib/xorg-nvidia-525.116.04/lib/x86_64-linux-gnu\",\n",
    "    \"/usr/lib/xorg/lib/x86_64-linux-gnu\",\n",
    "    \"/usr/lib/xorg-nvidia-535.113.01/lib/x86_64-linux-gnu\"\n",
    "]\n",
    "\n",
    "# Current LD_LIBRARY_PATH from the environment\n",
    "current_ld_library_path = os.environ.get('LD_LIBRARY_PATH', '')\n",
    "\n",
    "# Adding each path only if it is not already in the LD_LIBRARY_PATH\n",
    "new_paths = [path for path in library_paths if path not in current_ld_library_path]\n",
    "\n",
    "# Join all new paths with the existing LD_LIBRARY_PATH\n",
    "os.environ['LD_LIBRARY_PATH'] = ':'.join(new_paths + [current_ld_library_path])\n",
    "\n",
    "# Verify the update\n",
    "print(\"Updated LD_LIBRARY_PATH:\")\n",
    "print(os.environ['LD_LIBRARY_PATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:47:01,327\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-10-23 12:04:15</td></tr>\n",
       "<tr><td>Running for: </td><td>00:17:13.64        </td></tr>\n",
       "<tr><td>Memory:      </td><td>21.0/503.4 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: 0.37604042806183113 | Iter 5.000: 0.32877526753864444<br>Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: 0.27586206896551724<br>Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None<br>Logical resource usage: 4.0/24 CPUs, 2.0/4 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_acc</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TrainViT_c0a7d_00000</td><td>RUNNING </td><td>10.56.7.46:733248</td><td style=\"text-align: right;\">0.00495431</td><td style=\"text-align: right;\">  0.846764</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         987.36 </td><td style=\"text-align: right;\">    0.699733</td><td style=\"text-align: right;\">   0.83842 </td><td style=\"text-align: right;\">   3.11659</td></tr>\n",
       "<tr><td>TrainViT_c0a7d_00001</td><td>RUNNING </td><td>10.56.7.46:733249</td><td style=\"text-align: right;\">0.0241355 </td><td style=\"text-align: right;\">  0.886337</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         978.528</td><td style=\"text-align: right;\">    0.310892</td><td style=\"text-align: right;\">   0.923399</td><td style=\"text-align: right;\">   2.87255</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainViT pid=733249)\u001b[0m /home/sur06423/miniconda3/envs/deepl/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1704987280714/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "\u001b[36m(TrainViT pid=733249)\u001b[0m   return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th style=\"text-align: right;\">  train_acc</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_acc</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TrainViT_c0a7d_00000</td><td style=\"text-align: right;\">   0.83842 </td><td style=\"text-align: right;\">    0.699733</td><td style=\"text-align: right;\"> 0.302021</td><td style=\"text-align: right;\">   3.11659</td></tr>\n",
       "<tr><td>TrainViT_c0a7d_00001</td><td style=\"text-align: right;\">   0.923399</td><td style=\"text-align: right;\">    0.310892</td><td style=\"text-align: right;\"> 0.403389</td><td style=\"text-align: right;\">   2.87255</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 12:04:15,016\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-10-23 12:04:15,039\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/sur06423/ray_results/TrainViT_2024-10-23_11-47-01' in 0.0205s.\n",
      "2024-10-23 12:04:25,061\tINFO tune.py:1041 -- Total run time: 1043.73 seconds (1033.62 seconds for the tuning loop).\n",
      "2024-10-23 12:04:25,063\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"momentum\": tune.uniform(0.8, 0.99)\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    max_t=100,\n",
    "    grace_period=5,\n",
    "    reduction_factor=2,\n",
    "    brackets=3\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    TrainViT,\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
    "    num_samples=2,\n",
    "    scheduler=scheduler,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
