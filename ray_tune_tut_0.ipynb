{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using Ray Tune API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from ray import tune\n",
    "from ray.data import from_pandas\n",
    "from ray.train import RunConfig, ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.tune.tuner import Tuner\n",
    "\n",
    "def get_dataset():\n",
    "    data_raw = load_breast_cancer(as_frame=True)\n",
    "    dataset_df = data_raw[\"data\"]\n",
    "    dataset_df[\"target\"] = data_raw[\"target\"]\n",
    "    dataset = from_pandas(dataset_df)\n",
    "    return dataset\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    label_column=\"target\",\n",
    "    params={},\n",
    "    datasets={\"train\": get_dataset()},\n",
    ")\n",
    "\n",
    "param_space = {\n",
    "    \"scaling_config\": ScalingConfig(\n",
    "        num_workers=tune.grid_search([2, 4]),\n",
    "        resources_per_worker={\n",
    "            \"CPU\": tune.grid_search([1, 2]),\n",
    "        },\n",
    "    ),\n",
    "    # You can even grid search various datasets in Tune.\n",
    "    # \"datasets\": {\n",
    "    #     \"train\": tune.grid_search(\n",
    "    #         [ds1, ds2]\n",
    "    #     ),\n",
    "    # },\n",
    "    \"params\": {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"tree_method\": \"approx\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "        \"eta\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"subsample\": tune.uniform(0.5, 1.0),\n",
    "        \"max_depth\": tune.randint(1, 9),\n",
    "    },\n",
    "}\n",
    "tuner = Tuner(trainable=trainer, param_space=param_space,\n",
    "    run_config=RunConfig(name=\"my_tune_run\"))\n",
    "results = tuner.fit()\n",
    "\n",
    "\n",
    "import random\n",
    "from ray import train, tune\n",
    "def random_error_trainable(config):\n",
    "    if random.random() < 0.5:\n",
    "        return {\"loss\": 0.0}\n",
    "    else:\n",
    "        raise ValueError(\"This is an error\")\n",
    "tuner = tune.Tuner(\n",
    "    random_error_trainable,\n",
    "    run_config=train.RunConfig(name=\"example-experiment\"),\n",
    "    tune_config=tune.TuneConfig(num_samples=10),\n",
    ")\n",
    "try:\n",
    "    result_grid = tuner.fit()\n",
    "except ValueError:\n",
    "    pass\n",
    "for i in range(len(result_grid)):\n",
    "    result = result_grid[i]\n",
    "    if not result.error:\n",
    "            print(f\"Trial finishes successfully with metrics\"\n",
    "               f\"{result.metrics}.\")\n",
    "    else:\n",
    "            print(f\"Trial failed with error {result.error}.\")\n",
    "\n",
    "# Get the best result based on a particular metric.\n",
    "best_result = result_grid.get_best_result( \n",
    "    metric=\"loss\", mode=\"min\")\n",
    "# Get the best checkpoint corresponding to the best result.\n",
    "best_checkpoint = best_result.checkpoint \n",
    "# Get a dataframe for the last reported results of all of the trials\n",
    "df = result_grid.get_dataframe() \n",
    "# Get a dataframe for the minimum loss seen for each trial\n",
    "df = result_grid.get_dataframe(metric=\"loss\", mode=\"min\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define an objective fxn to optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, a, b):\n",
    "    return a * (x ** 0.5) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With the Function API, you can report intermediate metrics by simply calling ```train.report()``` within the function.\n",
    "- The ```config``` argument in the function is a dictionary populated automatically by Ray Tune and corresponding to the hyperparameters selected for the trial from the ```search space```.\n",
    "- Do not use ```train.report()``` within a ```Trainable``` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-10-20 11:56:13</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:03.16        </td></tr>\n",
       "<tr><td>Memory:      </td><td>17.6/503.4 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/80 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_863e1_00000</td><td>TERMINATED</td><td>10.56.7.46:350241</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">      0.00499034</td><td style=\"text-align: right;\">12.7178</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 11:56:13,463\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/sur06423/ray_results/trainable_2024-10-20_11-56-01' in 0.0238s.\n",
      "2024-10-20 11:56:13,470\tINFO tune.py:1041 -- Total run time: 7.12 seconds (3.14 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "\n",
    "def trainable(config: dict):\n",
    "    intermediate_score = 0\n",
    "    for x in range(20):\n",
    "        intermediate_score = objective(x, config[\"a\"], config[\"b\"])\n",
    "        train.report({\"score\": intermediate_score})  # This sends the score to Tune.\n",
    "\n",
    "\n",
    "tuner = tune.Tuner(trainable, param_space={\"a\": 2, \"b\": 4})\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class API Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class API Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from ray import train, tune\n",
    "\n",
    "\n",
    "class MyTrainableClass(tune.Trainable):\n",
    "    def setup(self, config):\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(config.get(\"input_size\", 32), 32), nn.ReLU(), nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "    def step(self):\n",
    "        return {}\n",
    "\n",
    "    def save_checkpoint(self, tmp_checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(tmp_checkpoint_dir, \"model.pth\")\n",
    "        torch.save(self.model.state_dict(), checkpoint_path)\n",
    "        return tmp_checkpoint_dir\n",
    "\n",
    "    def load_checkpoint(self, tmp_checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(tmp_checkpoint_dir, \"model.pth\")\n",
    "        self.model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    MyTrainableClass,\n",
    "    param_space={\"input_size\": 64},\n",
    "    run_config=train.RunConfig(\n",
    "        stop={\"training_iteration\": 2},\n",
    "        checkpoint_config=train.CheckpointConfig(checkpoint_frequency=2),\n",
    "    ),\n",
    ")\n",
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ray Tune supports callbacks that are called during various times of the training process. Callbacks can be passed as a parameter to RunConfig, taken in by Tuner, and the sub-method you provide will be invoked automatically.\n",
    "\n",
    "- This simple callback just prints a metric each time a result is received:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train, tune\n",
    "from ray.train import RunConfig\n",
    "from ray.tune import Callback\n",
    "\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def on_trial_result(self, iteration, trials, trial, result, **info):\n",
    "        print(f\"Got result: {result['metric']}\")\n",
    "\n",
    "\n",
    "def train_fn(config):\n",
    "    for i in range(10):\n",
    "        train.report({\"metric\": i})\n",
    "\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    train_fn,\n",
    "    run_config=RunConfig(callbacks=[MyCallback()]))\n",
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to report Metrcis in both APIs\n",
    "- You can log arbitrary values and metrics in both Function and Class training APIs:\n",
    "- Note that train.report() is not meant to transfer large amounts of data, like models or datasets. Doing so can incur large overheads and slow down your Tune run significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable(config):\n",
    "    for i in range(num_epochs):\n",
    "        ...\n",
    "        train.report({\"acc\": accuracy, \"metric_foo\": random_metric_1, \"bar\": metric_2})\n",
    "\n",
    "class Trainable(tune.Trainable):\n",
    "    def step(self):\n",
    "        ...\n",
    "        # don't call report here!\n",
    "        return dict(acc=accuracy, metric_foo=random_metric_1, bar=metric_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing Actors in Tune\n",
    "- Your Trainable can often take a long time to start. To avoid this, you can do tune.TuneConfig(reuse_actors=True) (which is taken in by Tuner) to reuse the same Trainable Python process and object for multiple hyperparameters.\n",
    "\n",
    "- This requires you to implement Trainable.reset_config, which provides a new set of hyperparameters. It is up to the user to correctly update the hyperparameters of your trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchTrainable(tune.Trainable):\n",
    "    \"\"\"Train a Pytorch ConvNet.\"\"\"\n",
    "\n",
    "    def setup(self, config):\n",
    "        self.train_loader, self.test_loader = get_data_loaders()\n",
    "        self.model = ConvNet()\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=config.get(\"lr\", 0.01),\n",
    "            momentum=config.get(\"momentum\", 0.9))\n",
    "\n",
    "    def reset_config(self, new_config):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            if \"lr\" in new_config:\n",
    "                param_group[\"lr\"] = new_config[\"lr\"]\n",
    "            if \"momentum\" in new_config:\n",
    "                param_group[\"momentum\"] = new_config[\"momentum\"]\n",
    "\n",
    "        self.model = ConvNet()\n",
    "        self.config = new_config\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Sample a float uniformly between -5.0 and -1.0\n",
    "    \"uniform\": tune.uniform(-5, -1),\n",
    "\n",
    "    # Sample a float uniformly between 3.2 and 5.4,\n",
    "    # rounding to multiples of 0.2\n",
    "    \"quniform\": tune.quniform(3.2, 5.4, 0.2),\n",
    "\n",
    "    # Sample a float uniformly between 0.0001 and 0.01, while\n",
    "    # sampling in log space\n",
    "    \"loguniform\": tune.loguniform(1e-4, 1e-2),\n",
    "\n",
    "    # Sample a float uniformly between 0.0001 and 0.1, while\n",
    "    # sampling in log space and rounding to multiples of 0.00005\n",
    "    \"qloguniform\": tune.qloguniform(1e-4, 1e-1, 5e-5),\n",
    "\n",
    "    # Sample a random float from a normal distribution with\n",
    "    # mean=10 and sd=2\n",
    "    \"randn\": tune.randn(10, 2),\n",
    "\n",
    "    # Sample a random float from a normal distribution with\n",
    "    # mean=10 and sd=2, rounding to multiples of 0.2\n",
    "    \"qrandn\": tune.qrandn(10, 2, 0.2),\n",
    "\n",
    "    # Sample a integer uniformly between -9 (inclusive) and 15 (exclusive)\n",
    "    \"randint\": tune.randint(-9, 15),\n",
    "\n",
    "    # Sample a random uniformly between -21 (inclusive) and 12 (inclusive (!))\n",
    "    # rounding to multiples of 3 (includes 12)\n",
    "    # if q is 1, then randint is called instead with the upper bound exclusive\n",
    "    \"qrandint\": tune.qrandint(-21, 12, 3),\n",
    "\n",
    "    # Sample a integer uniformly between 1 (inclusive) and 10 (exclusive),\n",
    "    # while sampling in log space\n",
    "    \"lograndint\": tune.lograndint(1, 10),\n",
    "\n",
    "    # Sample a integer uniformly between 1 (inclusive) and 10 (inclusive (!)),\n",
    "    # while sampling in log space and rounding to multiples of 2\n",
    "    # if q is 1, then lograndint is called instead with the upper bound exclusive\n",
    "    \"qlograndint\": tune.qlograndint(1, 10, 2),\n",
    "\n",
    "    # Sample an option uniformly from the specified choices\n",
    "    \"choice\": tune.choice([\"a\", \"b\", \"c\"]),\n",
    "\n",
    "    # Sample from a random function, in this case one that\n",
    "    # depends on another value from the search space\n",
    "    \"func\": tune.sample_from(lambda spec: spec.config.uniform * 0.01),\n",
    "\n",
    "    # Do a grid search over these values. Every value will be sampled\n",
    "    # ``num_samples`` times (``num_samples`` is the parameter you pass to ``tune.TuneConfig``,\n",
    "    # which is taken in by ``Tuner``)\n",
    "    \"grid\": tune.grid_search([32, 64, 128])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Search Algorithms (tune.search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tune’s Search Algorithms are wrappers around open-source optimization libraries for efficient hyperparameter selection. Each library has a specific way of defining the search space - please refer to their documentation for more details. Tune will automatically convert search spaces passed to Tuner to the library format in most cases.\n",
    "\n",
    "- You can utilize these search algorithms as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train, tune\n",
    "from ray.train import RunConfig\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "\n",
    "def train_fn(config):\n",
    "    # This objective function is just for demonstration purposes\n",
    "    train.report({\"loss\": config[\"param\"]})\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    train_fn,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=OptunaSearch(),\n",
    "        num_samples=100,\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "    param_space={\"param\": tune.uniform(0, 1)},\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
